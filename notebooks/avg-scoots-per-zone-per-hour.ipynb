{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc59714a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Point\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import date, timedelta, datetime\n",
    "import geopandas as gpd\n",
    "import folium\n",
    "from folium.plugins import MarkerCluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb8398f",
   "metadata": {},
   "source": [
    "loading may data - pickle and csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447c91be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "loc_pkl = pd.read_pickle(\"../data/july.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bd8bc1",
   "metadata": {},
   "source": [
    "## SECTION: DICTIONARY OF TIME-SEGMENT DATAFRAMES\n",
    "This section makes a dictionary of dataframes. The dataframes can be \"chunked up\" into different time segments. The main things you need to adjust: the start and end variables, and the delta variable, which designates how \"big\" a \"time chunk\" should be. Datetime docs here: https://docs.python.org/3/library/datetime.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1d24ad",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#make a list of datetimes with datetime function \n",
    "start = datetime(2019, 7, 4, 0, 0)\n",
    "end = datetime(2019, 7, 4, 23, 0)\n",
    "delta = timedelta(hours=1)\n",
    "timelist = []\n",
    "timenamelist = []\n",
    "while start <= end:\n",
    "    timelist.append(start)\n",
    "    timenamelist.append(start.strftime(\"%Y-%m-%d-%H-%M\"))\n",
    "    start += delta\n",
    "# print(timelist)\n",
    "# print(timenamelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7562016e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#goal of function: using list of time frames, in this case, days, make a dataframe containing\n",
    "#info about the location for each scooter, for each day\n",
    "\n",
    "\n",
    "#make dictionary of dataframes using base dataframe and a user-defined segments_of_time_list\n",
    "#from cell above\n",
    "def make_day_df(datetime_list, timenames_list, dataframe, colname):\n",
    "    resultslist = {} #turn into dictionary\n",
    "    x = 0\n",
    "    y = 1\n",
    "    z = 0\n",
    "    while x in range(0,len(datetime_list)-1):\n",
    "        starttime = datetime_list[x]\n",
    "        endtime = datetime_list[y]\n",
    "        mask = (dataframe[colname] > starttime) & (dataframe[colname] <= endtime)\n",
    "        framename = dataframe.loc[mask]\n",
    "        x += 1\n",
    "        y += 1\n",
    "        print(x)\n",
    "        resultslist[timenames_list[z]] = framename\n",
    "        z += 1\n",
    "    return resultslist\n",
    "        \n",
    "df_dict = make_day_df(timelist, timenamelist, loc_pkl, \"pubdatetime\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11494a65",
   "metadata": {},
   "source": [
    "## Converting Dictionary of DFs to Dictionary of GeoDFs, spatial-joined with Promise Zones for numerical analysis, not geospatial analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2788bd",
   "metadata": {},
   "source": [
    "This section below is experimental geospatial stuff, adapted from our geospatial notebook for the most part. IF you want to mess with this bit, make sure you load the notebook in the geospatial enivronment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2741a98d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "promise_zones = gpd.read_file('../data/MDHA_Promise_Zones/Export_Output_5.shp')\n",
    "print(promise_zones.crs)\n",
    "promise_zones= promise_zones.to_crs('EPSG:4326')\n",
    "print(promise_zones)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5609b1",
   "metadata": {},
   "source": [
    "### This cell bellow adds a geography column to each dataframe in the df_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b8191e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for key in df_dict:\n",
    "    working_df = df_dict[key]\n",
    "    working_df['geometry'] = working_df.apply(lambda x: Point(x['longitude'], \n",
    "                                                         x['latitude']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e708d47c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test it\n",
    "# df_dict['2019-05-10-19-00']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da36d99e",
   "metadata": {},
   "source": [
    "### Convert all dfs into geodfs, use promise zone crs, save in new dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aecfab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "geodf_dict = {}\n",
    "for key in df_dict:\n",
    "    geodf_dict[key] = gpd.GeoDataFrame(df_dict[key],\n",
    "                                  crs = promise_zones.crs,\n",
    "                                  geometry = df_dict[key]['geometry'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b52746",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test it\n",
    "# print(geodf_dict.keys())\n",
    "# print(type(geodf_dict['2019-05-10-00-00']))\n",
    "# print(geodf_dict['2019-05-10-00-00'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bf2a45",
   "metadata": {},
   "source": [
    "### Joining all geodfs in dict to promise zone "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6073e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in geodf_dict:\n",
    "    geodf_dict[key] = gpd.sjoin(geodf_dict[key], promise_zones, op=\"within\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b3da6e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#test it\n",
    "# geodf_dict['2019-05-11-06-00']['ZONE_ID'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3de6d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a dataframe of normalized scooter value counts each hour by zone\n",
    "scoots_by_hour_by_zone = pd.DataFrame()\n",
    "\n",
    "for key in geodf_dict:\n",
    "    the_series = geodf_dict[key]['ZONE_ID'].value_counts(normalize=True)\n",
    "    new_col = pd.DataFrame({\n",
    "                key : the_series\n",
    "    }\n",
    "    )\n",
    "    scoots_by_hour_by_zone = pd.concat([scoots_by_hour_by_zone,new_col], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc27add1",
   "metadata": {},
   "outputs": [],
   "source": [
    "scoots_by_hour_by_zone.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426944c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "scoots_by_hour_by_zone.to_csv(\"../data/scoots_by_zones_csvs/\" + str(start)[:10]+\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f89367d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2082fea2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a018e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621cb69a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a82241",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acbca7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9b859c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1b73e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ec9b7597",
   "metadata": {},
   "source": [
    "### Produce images for Gif!!! Make sure to change titlevar and savefig path to correct day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af969737",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#number of rows in promise zone id or in each zip\n",
    "the_hour = 0\n",
    "for key in geodf_dict:\n",
    "    leg_kwds = {'title': 'Promise Zone', 'loc': 'upper left', \n",
    "            'bbox_to_anchor': (1, 1.03), 'ncol': 1}\n",
    "    ax = promise_zones.plot(figsize = (8, 10), cmap='Set1', edgecolor = 'black',\n",
    "              legend = True, legend_kwds = leg_kwds)\n",
    "    geodf_dict[key].plot(ax = ax, column='sumdid')\n",
    "    titlevar = \"Thursday, July 4th, \" + str(the_hour) + \":00\" + \" to \" + str(the_hour + 1) + \":00\"\n",
    "    plt.title(titlevar)\n",
    "    the_hour += 1\n",
    "    plt.savefig(\"../maps/July_4_2019/\" + key + \"_map.png\")\n",
    "#     plt.show();\n",
    "\n",
    "# output_geodf_and_promise['ZONE_ID'].value_counts(normalize=True)\n",
    "# output_geodf_and_zip['zip'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
